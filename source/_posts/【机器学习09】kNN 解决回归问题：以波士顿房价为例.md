---
title: 【机器学习09】kNN 解决回归问题：以波士顿房价为例
id: Machine_learning11
date: 2019-6-21 16:16:16
categories: 机器学习
tags: [机器学习]
images: http://media.makcyun.top/win/20190621/dNtjN1JkDa70.png?imageslim
keywords: [机器学习K近邻算法,kNN线性回归,python boston房价] 
---

kNN 既可以解决分类问题也可以解决回归问题。

<!-- more -->  

**摘要：**以波士顿房价数据集为例，使用 kNN 模型解决回归问题——预测房价。

之前我们花了大量篇幅介绍使用 kNN 算法解决分类问题，其实 kNN 是少数机器学习算法中，既适合解决**分类问题**也适合解决**回归问题**的算法。

在 sklearn 中使用 `KNeighborsClassifier` 类解决分类，回归问题则可以调用 `KNeighborsRegressor`类。

![](http://media.makcyun.top/Fm6W-7AhyC1HScgsSuok_jJTuDr3)

先来回顾一下 kNN 是如何解决分类问题的。下图中，红绿色点表示两种类别，根据黄色点最近 K 个点的类别来评估其所属类别。假设 k 取 3 ，则黄色点大概率属于红色类别。

![](http://media.makcyun.top/FmXjNIibX90H0oAWljK4WnSEJ97C)

当要解决回归问题时，我们面对的问题不再是判断样本属于哪个类别，样本值也不是离散值而是连续的具体值。比如预测学生的成绩具体是多少分。

计算思路也很简单，主要分两步。**第一步和分类算法一样，找到离待预测节点最近的 K 个点，第二步则是取这 K 个节点值的平均值作为待预测点的预测值。**

![](http://media.makcyun.top/Fr_wzKiKbr0ZMx7czg0LZj0puF2Q)

是不是很简单？

下面我们就通过一个简单的数据集来熟悉一下 kNN 回归模型。

训练集有 6 个红色样本点，每个样本点有 X Y 两个特征，点的标签值分别是 1-6。现在需要预测绿色样本点的标签值。假设 k 取 3，很容易就能得到左下角的三个红点是离绿色点最近的，则绿点的标签值等于（1+2+3）/3=2。 当 k 取 5 时，绿色点的标签值等于（1+2+3+4+5）/5=3。

![](http://media.makcyun.top/FqTbxS7Yv6Vfvc540OxIzIaJcH9y)

编码实现如下：

![](http://media.makcyun.top/FmwgoTz3kre75Qk5tPE_RTDE2mui)

下面我们再用 kNN 的回归模型解决一个实际案例：**波士顿房价**。

波士顿房价是机器学习中很常用的一个解决回归问题的数据集。数据统计于 1978 年，包括 506个房价样本，每个样本包括波士顿不同郊区房屋的13 种特征信息，比如：住宅房间数、城镇教师和学生比例等。标签值则是每栋房子的房价（千美元）。所以这是一个小型数据集，有 506 * 14 维。

我们通过这几步来预测房价：

- 加载数据集并初步探索
- 划分训练集和测试集
- 对特征做均值方差归一化
- 建立 kNN 回归模型并预测

先加载数据集并做简单的初步探索。

![](http://media.makcyun.top/FoJRKZa7SDlauMyeioP6eIMuVjzz)

每个特征的含义如下：

- CRIM: 城镇人均犯罪率（%）
- ZN: 住宅用地所占比例（%）
- INDUS: 城镇中非住宅用地所占比例（%）
- CHAS: 0-1分类变量，是否靠近Charles River，靠近1，否则0
- NOX: 一氧化氮指数 
- RM: 每栋住宅的房间数
- AGE: 1940 年以前建成的自住单位的比例（%）
- DIS: 距离 5 个波士顿的就业中心的加权距离
- RAD: 距离高速公路的便利指数
- TAX: 每一万美元的不动产税率（%）
- PTRATIO: 城镇中的教师学生比例（%）
- B: 关于黑人比例的一个参数（%）
- LSTAT: 地区中有多少房东属于低收入人群（%）
- MEDV: 自住房屋房价中位数（也就是均价,单位千美元)

可以看到特征之间数值差异较大，所以最好先对数据做归一化再建立模型。

样本一共有 13 个特征，建立模型时可以纳入全部特征也可以只纳入部分，我们选择后者。使用 SelectKBest 方法可以筛选出和标签最相关的 K 个特征，这里选择和房价最相关的 3 个特征： 

- RM 
- PTRATIO 
- LSTAT

![](http://media.makcyun.top/FmzUOvqZ3Z-9IjQVKAdJ-GrGcdzF)

特征选择好之后，接下来划分数据集并归一化，然后建模，代码如下：

![](http://media.makcyun.top/FnpqWbL3Tp5_we2Aq9-wcQrSfkL8)

这样我们就计算出了房价预测值和相应的模型得分。

房价预测值和实际值见下图，可以看到预测效果总体还不错。

![](http://media.makcyun.top/FpdOOZVI8kxSw-FxCfmDi_D2kK19)

模型得分这里使用了**均方根误差（RMSE）和 R2_score** 来判断。

上图中，这两个值分别为 4.58 和 0.74。 

**均方根误差表示模型的偏离程度，越接近 0 越好**。此处 4.58 的含义就是说 68% 的预测房价值和真实房价（均值为 22.53）之间的差值在 4.58（一个标准差） 之间，也就是 68% 的房价位于 [18,27] 之间（单位千美元）。 95% 的房价位于均值的两个标准差之间，也就是 [13.5,31.5]。

**R2_score 表示模型拟合数据集的好坏，越接近1 表示拟合效果越好。**

为了比较不同模型的均方根误差和 R2 值，我们还可以使用之前说的**网格搜索**方法进一步优化模型。

![](http://media.makcyun.top/FpLk8tQ6e0aVYnITc4BFG67guTLO)

可以看到均方根误差降低到了 4.35 ，R2 值提升到了 0.76，说明网格搜索建立的模型效果更好。

![](http://media.makcyun.top/FiQW9yScNauclLBEGzKEfpofQ9yJ)

之后我们学习其他算法（比如线性回归）的时候还会再对这个数据集建立模型并计算得分。

本文的 jupyter notebook 代码，可以在公众号：「**高级农民工**」后台回复「**kNN9**」得到，加油！