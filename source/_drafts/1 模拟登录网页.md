---


title: Python爬虫(8)：模拟登录方法汇总
date: 2018-10-20 16:16:24
id: web_scraping_withpython8
categories: Python爬虫
tags: [Python爬虫,模拟登录]
images: http://pbscl931v.bkt.clouddn.com/Fnf-VlGgFGAb54iJ6MmH_3rnvPq0
keywords: [python模拟登录,python爬虫]
---

对于很多要先登录的网站来说，模拟登录往往是爬虫的第一道坎。

<!-- more -->  

**摘要：** 在进行爬虫时，除了会遇到一类不用登录就能爬的网站，还有一类需要登录的网站。比如豆瓣、知乎，有的甚至还需要再输入验证码，比如12306，通过打码平台进行人工打码。所以需要先登录再爬虫。

## 目标网页

这是我们要获取内容的网页：

![](http://pbscl931v.bkt.clouddn.com/18-10-19/68214534.jpg)



观察这个网站，是需要先登录才能看到数据信息的，但是好在不用输验证码。我们就需要利用账号密码，用代码来实现模拟登录。

这是我们要登录的网页。

![](http://pbscl931v.bkt.clouddn.com/18-10-17/98135777.jpg)



模拟登录的方法有好几种，比如post直接提交账号、先登录获取cookies、seleium模拟登录。其中：

- post方法相对麻烦，需要在后台获取登录的url，并填写表单参数；
- 先登录将获取到的cookies加入headers中，最后用**requests.get**方法提交，这种最为方便；
- selenium模拟登录是直接输入账号、密码，但速度会有点慢。

几种方法的具体对比，之后会单独写一篇文章介绍。这里，我们就采用第二种方法。

这里，我们需要先了解两个知识点：Session和Cookies。简单得来说：

> Session 在服务端，也就是网站的服务器，用来保存用户的会话信息，Cookies 在客户端，也可以理解为浏览器端，有了 Cookies，浏览器在下次访问网页时会自动附带上它发送给服务器，服务器通过识别 Cookies 并鉴定出是哪个用户，然后再判断用户是否是登录状态，然后返回对应的 Response。所以我们可以理解为 Cookies 里面保存了登录的凭证，有了它我们只需要在下次请求携带 Cookies 发送 Request 而不必重新输入用户名、密码等信息重新登录了。
> 因此在爬虫中，有时候处理需要登录才能访问的页面时，我们一般会直接将登录成功后获取的 Cookies 放在 Request Headers 里面直接请求。

下面，我们就正式尝试不同的方法。

## post提交账号请求登录

首先，我们要找到post请求的url。

有两种方法，第一种是后台网页请求查看，第二种是Fiddler软件中查看。

```python
import requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
    }
data = {
    'identity':'irw27812@awsoo.com',   
    'password':'test2018',
}
url ='https://www.itjuzi.com/user/login?redirect=&flag=&radar_coupon='
session = requests.Session()
session.post(url,headers = headers,data = data)
response = session.get('http://radar.itjuzi.com/investevent',headers = headers)
print(response.status_code)
print(response.text)
```

可以成功请求网页内容了。

![](http://pbscl931v.bkt.clouddn.com/18-10-19/19273353.jpg)



## 获取cookies，直接请求登录

### requests请求登录

代码如下：

```python
import requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
    'Cookie': '你的cookie',
}
url = 'https://www.itjuzi.com/user/login?redirect=&flag=&radar_coupon='
session = requests.Session()
response = session.get('http://radar.itjuzi.com/investevent', headers=headers)

print(response.status_code)
print(response.text)
```





![](http://pbscl931v.bkt.clouddn.com/18-10-19/5798761.jpg)

## selenium模拟登录

代码如下：

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait
browser = webdriver.Chrome()
browser.maximize_window()  # 最大化窗口
wait = WebDriverWait(browser, 10)

def login():
    browser.get('https://www.itjuzi.com/user/login')
    input = wait.until(EC.presence_of_element_located(
        (By.XPATH, '//*[@id="create_account_email"]')))
    input.send_keys('irw27812@awsoo.com')
    input = wait.until(EC.presence_of_element_located(
        (By.XPATH, '//*[@id="create_account_password"]')))
    input.send_keys('test2018')
    submit = wait.until(EC.element_to_be_clickable(
        (By.XPATH, '//*[@id="login_btn"]')))
    submit.click()
    get_page_index()

def get_page_index():
    browser.get('http://radar.itjuzi.com/investevent')
    try:
        print(browser.page_source)  # 查看网页源码
    except Exception as e:
        print(str(e))
login()

```

结果如下：

![](http://pbscl931v.bkt.clouddn.com/18-10-19/8322177.jpg)



## 总结：

- 建议优先选择先获取cookies再请求的方法
- 这里模拟登录的网站，没有输入验证码。但是还有很多网站还需要输入验证码才能登录，后续将介绍验证码的处理方法。

参考：

> [http://docs.python-requests.org/zh_CN/latest/user/advanced.html](http://docs.python-requests.org/zh_CN/latest/user/advanced.html)

本文完。

![](http://pbscl931v.bkt.clouddn.com/%E5%85%AC%E4%BC%97%E5%8F%B7%E5%85%B3%E6%B3%A8.jpg)

<center>欢迎扫一扫识别关注我的公众号</center>